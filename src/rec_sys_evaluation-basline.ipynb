{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba2b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b63f3",
   "metadata": {},
   "source": [
    "## Data Handling Process\n",
    "\n",
    "### 1. **Load Metadata**:\n",
    "   - The metadata is loaded from `id_metadata.csv`, using tab (`'\\t'`) as the delimiter, into the `metadata_df` DataFrame.\n",
    "\n",
    "### 2. **Load Listening History**:\n",
    "   - Listening history data is loaded from `listening_history.csv` into the `df` DataFrame.\n",
    "\n",
    "### 3. **Convert Timestamps**:\n",
    "   - The `timestamp` column in `df` is converted to datetime format to facilitate time-based operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081a5611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>DaTQ53TUmfP93FSr</td>\n",
       "      <td>2019-02-20 12:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>dGeyvi5WCOjDU7da</td>\n",
       "      <td>2019-02-20 12:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>qUm54NYOjeFhmKYx</td>\n",
       "      <td>2019-02-20 12:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>FtnuMT1DlevSR2n5</td>\n",
       "      <td>2019-02-20 12:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>LHETTZcSZLeaVOGh</td>\n",
       "      <td>2019-02-20 13:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109587</th>\n",
       "      <td>user_zzWscYTy</td>\n",
       "      <td>BBiswLufo26YQCT7</td>\n",
       "      <td>2019-01-10 15:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109588</th>\n",
       "      <td>user_zzWscYTy</td>\n",
       "      <td>5ZHgff3sjETIiedr</td>\n",
       "      <td>2019-01-10 16:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109589</th>\n",
       "      <td>user_zzWscYTy</td>\n",
       "      <td>m4O1iLh6fC43xjRy</td>\n",
       "      <td>2019-01-10 16:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109590</th>\n",
       "      <td>user_zzWscYTy</td>\n",
       "      <td>mvUaP8k67qOFfA65</td>\n",
       "      <td>2019-01-10 21:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109591</th>\n",
       "      <td>user_zzWscYTy</td>\n",
       "      <td>BBiswLufo26YQCT7</td>\n",
       "      <td>2019-01-10 21:16:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5109592 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user              song           timestamp\n",
       "0        user_007XIjOr  DaTQ53TUmfP93FSr 2019-02-20 12:28:00\n",
       "1        user_007XIjOr  dGeyvi5WCOjDU7da 2019-02-20 12:35:00\n",
       "2        user_007XIjOr  qUm54NYOjeFhmKYx 2019-02-20 12:48:00\n",
       "3        user_007XIjOr  FtnuMT1DlevSR2n5 2019-02-20 12:52:00\n",
       "4        user_007XIjOr  LHETTZcSZLeaVOGh 2019-02-20 13:09:00\n",
       "...                ...               ...                 ...\n",
       "5109587  user_zzWscYTy  BBiswLufo26YQCT7 2019-01-10 15:57:00\n",
       "5109588  user_zzWscYTy  5ZHgff3sjETIiedr 2019-01-10 16:21:00\n",
       "5109589  user_zzWscYTy  m4O1iLh6fC43xjRy 2019-01-10 16:48:00\n",
       "5109590  user_zzWscYTy  mvUaP8k67qOFfA65 2019-01-10 21:13:00\n",
       "5109591  user_zzWscYTy  BBiswLufo26YQCT7 2019-01-10 21:16:00\n",
       "\n",
       "[5109592 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = '../data/id_metadata.csv'\n",
    "listening_history_path = '../data/listening_history.csv'\n",
    "metadata_df = pd.read_csv(metadata_path, delimiter='\\t')\n",
    "df = pd.read_csv(listening_history_path, delimiter='\\t')\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68829bcc",
   "metadata": {},
   "source": [
    "## Data Filtering Process Based on Recent Dates\n",
    "\n",
    "### 1. **Determine Latest Date**:\n",
    "   - Calculate the most recent date (`latest_date`) in the `timestamp` column of the DataFrame `df`.\n",
    "\n",
    "### 2. **Compute Date for One Week Ago**:\n",
    "   - Subtract 7 days from the `latest_date` using `pd.Timedelta`, resulting in the date `one_week_ago`.\n",
    "\n",
    "### 3. **Filter Recent Data**:\n",
    "   - Restrict `df` to only include rows where the `timestamp` is on or after `one_week_ago`, effectively filtering the data to the last week.\n",
    "\n",
    "### 4. **Output Filtered DataFrame**:\n",
    "   - The resulting DataFrame `df` now contains only the records from the past week, ready for analysis or further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cc780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>ke5JKpLa8Dw7dCDO</td>\n",
       "      <td>2019-03-19 12:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>nRpEFcFzYZ8Z8Cye</td>\n",
       "      <td>2019-03-19 12:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>UTDxdZ1outySsU7O</td>\n",
       "      <td>2019-03-19 15:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>UTDxdZ1outySsU7O</td>\n",
       "      <td>2019-03-19 15:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>bxo3drSzBGDlrodp</td>\n",
       "      <td>2019-03-19 15:24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104162</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>A8GhNkPLuKusMIvF</td>\n",
       "      <td>2019-03-21 18:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104163</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>0m1MyuwLx1EjuQqD</td>\n",
       "      <td>2019-03-21 22:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104164</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>0m1MyuwLx1EjuQqD</td>\n",
       "      <td>2019-03-21 22:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104165</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>l2kISVY4j8iz1Gg7</td>\n",
       "      <td>2019-03-21 22:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104166</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>l2kISVY4j8iz1Gg7</td>\n",
       "      <td>2019-03-21 22:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68090 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user              song           timestamp\n",
       "5288     user_02jFGVkG  ke5JKpLa8Dw7dCDO 2019-03-19 12:39:00\n",
       "5289     user_02jFGVkG  nRpEFcFzYZ8Z8Cye 2019-03-19 12:44:00\n",
       "5290     user_02jFGVkG  UTDxdZ1outySsU7O 2019-03-19 15:18:00\n",
       "5291     user_02jFGVkG  UTDxdZ1outySsU7O 2019-03-19 15:24:00\n",
       "5292     user_02jFGVkG  bxo3drSzBGDlrodp 2019-03-19 15:24:00\n",
       "...                ...               ...                 ...\n",
       "5104162  user_zwQunLVn  A8GhNkPLuKusMIvF 2019-03-21 18:29:00\n",
       "5104163  user_zwQunLVn  0m1MyuwLx1EjuQqD 2019-03-21 22:29:00\n",
       "5104164  user_zwQunLVn  0m1MyuwLx1EjuQqD 2019-03-21 22:33:00\n",
       "5104165  user_zwQunLVn  l2kISVY4j8iz1Gg7 2019-03-21 22:36:00\n",
       "5104166  user_zwQunLVn  l2kISVY4j8iz1Gg7 2019-03-21 22:40:00\n",
       "\n",
       "[68090 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_date = df['timestamp'].max()\n",
    "one_week_ago = latest_date - pd.Timedelta(days=7)\n",
    "df = df[df['timestamp'] >= one_week_ago]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f37d6b",
   "metadata": {},
   "source": [
    "## DataFrame Operations Overview\n",
    "\n",
    "### 1. **Check for Missing Values**:\n",
    "   - `df.isnull().sum()` calculates the total number of missing values in each column of the DataFrame.\n",
    "   \n",
    "### 2. **Identify Unique Entries**:\n",
    "   - `df.song.unique()` retrieves an array of unique song IDs from the `song` column.\n",
    "   - `df.user.unique()` retrieves an array of unique user IDs from the `user` column.\n",
    "\n",
    "### 3. **Calculate Song Popularity**:\n",
    "   - The popularity of each song is calculated as the frequency of the song's appearance in the DataFrame divided by the total number of unique songs.\n",
    "   - This calculated popularity is then mapped back to the `song` column of `df` and stored in a new column `song_popularity`.\n",
    "\n",
    "The final DataFrame `df` is enhanced with a new `song_popularity` column which provides a relative measure of how frequently each song appears in the dataset, adjusted by the number of unique songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340a6e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user         0\n",
       "song         0\n",
       "timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5beebee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18193,), (633,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names_song = df.song.unique()\n",
    "unique_names_user = df.user.unique()\n",
    "unique_names_song.shape, unique_names_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a570b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olko\\AppData\\Local\\Temp\\ipykernel_11016\\129118991.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['song_popularity'] = df['song'].map(song_popularity)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>song_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>ke5JKpLa8Dw7dCDO</td>\n",
       "      <td>2019-03-19 12:39:00</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>nRpEFcFzYZ8Z8Cye</td>\n",
       "      <td>2019-03-19 12:44:00</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>UTDxdZ1outySsU7O</td>\n",
       "      <td>2019-03-19 15:18:00</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>UTDxdZ1outySsU7O</td>\n",
       "      <td>2019-03-19 15:24:00</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>user_02jFGVkG</td>\n",
       "      <td>bxo3drSzBGDlrodp</td>\n",
       "      <td>2019-03-19 15:24:00</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104162</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>A8GhNkPLuKusMIvF</td>\n",
       "      <td>2019-03-21 18:29:00</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104163</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>0m1MyuwLx1EjuQqD</td>\n",
       "      <td>2019-03-21 22:29:00</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104164</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>0m1MyuwLx1EjuQqD</td>\n",
       "      <td>2019-03-21 22:33:00</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104165</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>l2kISVY4j8iz1Gg7</td>\n",
       "      <td>2019-03-21 22:36:00</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104166</th>\n",
       "      <td>user_zwQunLVn</td>\n",
       "      <td>l2kISVY4j8iz1Gg7</td>\n",
       "      <td>2019-03-21 22:40:00</td>\n",
       "      <td>0.000879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68090 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user              song           timestamp  song_popularity\n",
       "5288     user_02jFGVkG  ke5JKpLa8Dw7dCDO 2019-03-19 12:39:00         0.000220\n",
       "5289     user_02jFGVkG  nRpEFcFzYZ8Z8Cye 2019-03-19 12:44:00         0.000715\n",
       "5290     user_02jFGVkG  UTDxdZ1outySsU7O 2019-03-19 15:18:00         0.000110\n",
       "5291     user_02jFGVkG  UTDxdZ1outySsU7O 2019-03-19 15:24:00         0.000110\n",
       "5292     user_02jFGVkG  bxo3drSzBGDlrodp 2019-03-19 15:24:00         0.000110\n",
       "...                ...               ...                 ...              ...\n",
       "5104162  user_zwQunLVn  A8GhNkPLuKusMIvF 2019-03-21 18:29:00         0.000055\n",
       "5104163  user_zwQunLVn  0m1MyuwLx1EjuQqD 2019-03-21 22:29:00         0.000879\n",
       "5104164  user_zwQunLVn  0m1MyuwLx1EjuQqD 2019-03-21 22:33:00         0.000879\n",
       "5104165  user_zwQunLVn  l2kISVY4j8iz1Gg7 2019-03-21 22:36:00         0.000879\n",
       "5104166  user_zwQunLVn  l2kISVY4j8iz1Gg7 2019-03-21 22:40:00         0.000879\n",
       "\n",
       "[68090 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()\n",
    "song_popularity = df['song'].value_counts() / len(unique_names_song)\n",
    "df['song_popularity'] = df['song'].map(song_popularity)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb07941",
   "metadata": {},
   "source": [
    "## Building Interaction Matrix and Enriched Data\n",
    "\n",
    "### 1. **Initialize Interaction Matrix**:\n",
    "   - An interaction matrix is created with dimensions corresponding to the unique count of users and songs, initialized with zeros.\n",
    "\n",
    "### 2. **Map Users and Songs to Matrix Indices**:\n",
    "   - Dictionaries `user_indices` and `song_indices` are created to map user and song identifiers to matrix indices for easy access.\n",
    "\n",
    "### 3. **Populate Interaction Matrix**:\n",
    "   - Iterate through the DataFrame `df`, using mapped indices to fill the matrix with the logarithm of song popularity incremented by one, to factor in popularity dynamics in interactions.\n",
    "\n",
    "### 5. **Prepare Data for Detailed Interaction DataFrame**:\n",
    "   - Arrays are prepared for user IDs, song IDs and interaction values by iterating over the interaction matrix for each song-user pair.\n",
    "\n",
    "### 6. **Construct Feature-Rich DataFrame**:\n",
    "   - A new DataFrame `interaction_df` is created to encapsulate user IDs, song IDs and their interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2be7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516164</th>\n",
       "      <td>632</td>\n",
       "      <td>18188</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516165</th>\n",
       "      <td>632</td>\n",
       "      <td>18189</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516166</th>\n",
       "      <td>632</td>\n",
       "      <td>18190</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516167</th>\n",
       "      <td>632</td>\n",
       "      <td>18191</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516168</th>\n",
       "      <td>632</td>\n",
       "      <td>18192</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11516169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  song_id  interaction\n",
       "0               0        0     0.000220\n",
       "1               0        1     0.000714\n",
       "2               0        2     0.000110\n",
       "3               0        3     0.000110\n",
       "4               0        4     0.000110\n",
       "...           ...      ...          ...\n",
       "11516164      632    18188     0.000055\n",
       "11516165      632    18189     0.000055\n",
       "11516166      632    18190     0.000055\n",
       "11516167      632    18191     0.000055\n",
       "11516168      632    18192     0.000055\n",
       "\n",
       "[11516169 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix = np.zeros((df['user'].nunique(), len(unique_names_song)))\n",
    "\n",
    "# Map users and songs to matrix indices\n",
    "user_indices = {user: idx for idx, user in enumerate(df['user'].unique())}\n",
    "song_indices = {song: idx for idx, song in enumerate(unique_names_song)}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_idx = user_indices[row['user']]\n",
    "    song_idx = song_indices[row['song']]\n",
    "    interaction_matrix[user_idx, song_idx] = np.log(row['song_popularity'] + 1)\n",
    "\n",
    "# Create lists for DataFrame\n",
    "user_ids, song_ids,  interactions = [], [], []\n",
    "for user in user_indices:\n",
    "    for song in song_indices:\n",
    "        user_ids.append(user_indices[user])\n",
    "        song_ids.append(song_indices[song])\n",
    "        interactions.append(interaction_matrix[user_indices[user], song_indices[song]])\n",
    "\n",
    "# Create the interaction DataFrame\n",
    "interaction_df = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'song_id': song_ids,\n",
    "    'interaction': interactions\n",
    "})\n",
    "\n",
    "interaction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a19f37",
   "metadata": {},
   "source": [
    "## Data Encoding and Basic Statistics\n",
    "\n",
    "### 1. **Encode User and Song Identifiers**:\n",
    "   - `LabelEncoder` is used to transform non-numeric user and song identifiers into numeric representations. The transformed identifiers are stored in new columns `user_id` and `song_id` in the DataFrame `df`.\n",
    "\n",
    "### 2. **Calculate Unique Counts**:\n",
    "   - Calculate the number of unique users (`N`) and the number of unique songs (`M`) from the newly encoded `user_id` and `song_id` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9d8b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 18193\n",
      "(68090, 6) (11516169, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olko\\AppData\\Local\\Temp\\ipykernel_11016\\447069982.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['user_id'] = user_encoder.fit_transform(df['user'])\n",
      "C:\\Users\\olko\\AppData\\Local\\Temp\\ipykernel_11016\\447069982.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['song_id'] = song_encoder.fit_transform(df['song'])\n"
     ]
    }
   ],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "song_encoder = LabelEncoder()\n",
    "df['user_id'] = user_encoder.fit_transform(df['user'])\n",
    "df['song_id'] = song_encoder.fit_transform(df['song'])\n",
    "\n",
    "N = df.user_id.nunique()  # Number of users\n",
    "M = df.song_id.nunique()  # Number of songs\n",
    "\n",
    "print(N, M)\n",
    "print(df.shape, interaction_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5643a",
   "metadata": {},
   "source": [
    "## Data Splitting and Exploration\n",
    "\n",
    "### 1. **Split Data into Training and Testing Sets**:\n",
    "   - The `interaction_df` DataFrame is split into training (`df_train`) and testing sets (`df_test`) using a 20% test size allocation and a random seed for reproducibility.\n",
    "\n",
    "### 2. **Evaluate Unique Interaction Values**:\n",
    "   - Determine the number of unique interaction values within the `df_train` using `interaction.nunique()` to understand the diversity of user-song interactions.\n",
    "\n",
    "### 4. **Check for Missing Values**:\n",
    "   - Calculate and display the total count of missing values per column in both `df_train` and `df_test` using `isnull().sum()` to assess data cleanliness and readiness for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b27781d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3437593</th>\n",
       "      <td>188</td>\n",
       "      <td>17309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363724</th>\n",
       "      <td>569</td>\n",
       "      <td>11907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280692</th>\n",
       "      <td>345</td>\n",
       "      <td>4107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531948</th>\n",
       "      <td>194</td>\n",
       "      <td>2506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391169</th>\n",
       "      <td>241</td>\n",
       "      <td>6656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234489</th>\n",
       "      <td>122</td>\n",
       "      <td>14943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304572</th>\n",
       "      <td>236</td>\n",
       "      <td>11024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10081351</th>\n",
       "      <td>554</td>\n",
       "      <td>2429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550634</th>\n",
       "      <td>360</td>\n",
       "      <td>1154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423388</th>\n",
       "      <td>353</td>\n",
       "      <td>1259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9212935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  song_id  interaction\n",
       "3437593       188    17309          0.0\n",
       "10363724      569    11907          0.0\n",
       "6280692       345     4107          0.0\n",
       "3531948       194     2506          0.0\n",
       "4391169       241     6656          0.0\n",
       "...           ...      ...          ...\n",
       "2234489       122    14943          0.0\n",
       "4304572       236    11024          0.0\n",
       "10081351      554     2429          0.0\n",
       "6550634       360     1154          0.0\n",
       "6423388       353     1259          0.0\n",
       "\n",
       "[9212935 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(interaction_df, test_size=0.2, random_state=42)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb41ea93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.interaction.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f8855a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id        0\n",
       "song_id        0\n",
       "interaction    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2859786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id        0\n",
       "song_id        0\n",
       "interaction    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b87a6",
   "metadata": {},
   "source": [
    "## Model Loading and Inspection\n",
    "\n",
    "### 1. **Load Pre-trained Model**:\n",
    "   - The Keras model is loaded from a specified path (`model_path`), where it was previously saved as `baseline-model.h5`.\n",
    "\n",
    "### 2. **Display Model Architecture**:\n",
    "   - Use `model.summary()` to print the structure of the model. This includes details of all layers, their types, outputs, and the number of parameters both trainable and non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3661c114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 15)        9495        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 15)        272895      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 1)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 1, 1)         633         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 1)         18193       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1, 1)         0           ['dot[0][0]',                    \n",
      "                                                                  'embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1)            0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,216\n",
      "Trainable params: 301,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = '../helpers/baseline-model.h5'\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68382970",
   "metadata": {},
   "source": [
    "## Predictive Model Input Preparation and Execution\n",
    "\n",
    "### 1. **Select Specific User**:\n",
    "   - A specific user (`specific_user_id`) is selected from the test data to focus the predictions on.\n",
    "\n",
    "### 2. **Prepare User Input Array**:\n",
    "   - Create an array `user_input` where the selected user’s ID is repeated for each song, ensuring each song is paired with the user for prediction purposes.\n",
    "\n",
    "### 3. **Prepare Song Input Array**:\n",
    "   - Generate `song_input` as an array of indices representing all unique songs (`M` is the total count of unique songs).\n",
    "\n",
    "### 4. **Map Song IDs to DataFrame Indices**:\n",
    "   - Construct a dictionary `song_id_to_index` that maps each song ID to its corresponding index in `interaction_df` for efficient data retrieval.\n",
    "\n",
    "### 5. **Execute Predictions**:\n",
    "   - Make predictions for all songs for the selected user using the prepared inputs (`user_input`, `song_input`). \n",
    "\n",
    "### 6. **Adjust Predictions**:\n",
    "   - Normalize predicted interactions by adding the mean interaction value (`mu`) from the training set to each prediction, compensating for any baseline shifts in interaction levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c534083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 562us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00088141, -0.00157933, -0.0007543 , ...,  0.00566827,\n",
       "       -0.00082867, -0.00432805], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids_test = df_test.user_id.values\n",
    "song_ids_test = df_test.song_id.values\n",
    "\n",
    "# Select a specific user for the prediction\n",
    "specific_user_id = user_ids_test[0]\n",
    "\n",
    "# Prepare input data for the model\n",
    "M = interaction_df['song_id'].nunique()  # Total number of unique songs\n",
    "user_input = np.array([specific_user_id] * M)  # Repeat the user ID for each song\n",
    "song_input = np.array(range(M))  # Array of all unique song IDs\n",
    "\n",
    "# Map song IDs to indices in df\n",
    "song_id_to_index = {id: idx for idx, id in enumerate(interaction_df['song_id'].unique())}\n",
    "\n",
    "# Make predictions for this user with all songs\n",
    "predicted_interactions = model.predict([user_input, song_input])\n",
    "\n",
    "mu = df_train.interaction.mean()  # Mean interaction value for normalization\n",
    "predicted_interactions = predicted_interactions.flatten() + mu\n",
    "predicted_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fbad0",
   "metadata": {},
   "source": [
    "## Extracting Top Song Recommendations\n",
    "\n",
    "### 1. **Determine Number of Recommendations**:\n",
    "   - Define `N` as 10 to specify the number of top recommendations to be retrieved.\n",
    "\n",
    "### 2. **Identify Top Recommendations**:\n",
    "   - Use `np.argsort()` on the `predicted_interactions` array to get indices of songs sorted by predicted interaction strength.\n",
    "   - Reverse the order (`[::-1]`) to start with the highest values and select the top `N` indices (`top_n_indices`).\n",
    "\n",
    "### 3. **Map Indices to Original Song IDs**:\n",
    "   - Convert the top indices (`top_n_indices`) back to original song IDs using the `song_encoder.inverse_transform()` function, yielding `top_n_song_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4619a677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommended song IDs for user 277 are: ['BajuXAK1vYSV9DqI' 'A561aRQ5xWskGyTy' 'XCh4gauugO7p5yEq'\n",
      " '0lHFJ5a22QJltO8s' 'QDtAFWCvEaRwFPnC' '2iuSNjkeDoqs4zjd'\n",
      " 'DyoJSQa9jxP6YjKw' 'RwP7Pv5i89I1rHvi' 'Su1CX9btXIQzVWUY'\n",
      " 'prOM9bF9uzuC4rqR']\n",
      "(18193,)\n",
      "(18193,)\n",
      "['wG3YQktIKVlZruUu' 'J4tQCUzKKKj3OkV0' 'AWLAvZOhu4vLV6RA'\n",
      " 'b5ef6NhN3RBrQXIE' 'SAryWbXDkmkFWW3Z' 'GQoNBkAIX2obbtPn'\n",
      " 'Ax8Us7NbJqe08R0a' 'Br8x0lv4QnA6pnqC' 'ilrbbVMFVbnwmdFp'\n",
      " 'rPcvhlfan3sOTDX8' 'RCGLlYCigkopKd7D' '6WlGmqDauWacBf9D'\n",
      " 'vZ3hXeIO65MA9fBi' 's7f6VKariF11TTjK' 'aAXwzXQZdbdPxFqT'\n",
      " 'L6AP1Ype1fRuWBwD' '5yY4kVyuJPdbOegL' '2HgkT8eEkxxEo2Tg'\n",
      " 'bhOXqQHAGOeJqm6I' 'X8ZpmMJo8zT2QvcT' 'MwpFtrA5qYK4v5tl'\n",
      " '6U91Xztu28VOYkmU' 'NsNXlxbPuFnyPv9p' 'OBkwaSaAAVVcBaag']\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of top recommendations top 10\n",
    "N = 10\n",
    "top_n_indices = np.argsort(predicted_interactions)[::-1][:N]\n",
    "\n",
    "# Convert the indices to original song IDs\n",
    "top_n_song_ids = song_encoder.inverse_transform(top_n_indices)\n",
    "\n",
    "print(f\"Top {N} recommended song IDs for user {specific_user_id} are:\", top_n_song_ids)\n",
    "print(user_input.shape)\n",
    "print(song_input.shape)\n",
    "print(df[df.user_id == specific_user_id].song.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054a224",
   "metadata": {},
   "source": [
    "## Displaying Detailed Song Information for Recommendations\n",
    "\n",
    "### 1. **Load Song Metadata**:\n",
    "   - Import song metadata from `id_information.csv` using `pd.read_csv()`, specifying a tab (`'\\t'`) as the delimiter, into the DataFrame `id_information`.\n",
    "\n",
    "### 2. **Filter Relevant Song Details**:\n",
    "   - Filter `id_information` to include only the entries corresponding to the `top_n_song_ids`, which are the IDs of the top recommended songs. This is accomplished using the `isin()` method, ensuring that only relevant song information is considered.\n",
    "\n",
    "### 3. **Display Top Recommended Songs**:\n",
    "   - Print details of the top recommended songs specifically tailored for the user (`specific_user_id`). The details displayed include the artist, song title, and album name from the `recommended_songs` DataFrame.\n",
    "   - This step highlights the song information, providing a more meaningful context to the recommendations, such as knowing the artist and album for each recommended song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6f3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommended songs for user 277 are:\n",
      "                     artist  \\\n",
      "1372    Pinkshinyultrablast   \n",
      "4875               Gorillaz   \n",
      "17728       Brandy & Monica   \n",
      "20425  Ludwig van Beethoven   \n",
      "24578         Kylie Minogue   \n",
      "46270          iamamiwhoami   \n",
      "49352           Nicki Minaj   \n",
      "51068           beabadoobee   \n",
      "58665           Paula Abdul   \n",
      "91362       Hiroyuki Sawano   \n",
      "\n",
      "                                                    song  \\\n",
      "1372                                          Land's End   \n",
      "4875                                          Magic City   \n",
      "17728                                    The Boy Is Mine   \n",
      "20425  Symphony No. 7 in A Major, Op. 92: II. Allegretto   \n",
      "24578                                           Timebomb   \n",
      "46270                                          blue blue   \n",
      "49352                                    Roman's Revenge   \n",
      "51068                                     If You Want To   \n",
      "58665                                       Cold Hearted   \n",
      "91362                                              MARKS   \n",
      "\n",
      "                                       album_name  \n",
      "1372                      Everything Else Matters  \n",
      "4875                                  The Now Now  \n",
      "17728                     Hip Hop & R'N'B Anthems  \n",
      "20425  Beethoven, Van L.: Symphonies Nos. 2 and 7  \n",
      "24578                                    Timebomb  \n",
      "46270                                        BLUE  \n",
      "49352                        Pink Friday (Deluxe)  \n",
      "51068                                  Patched Up  \n",
      "58665                           Forever Your Girl  \n",
      "91362                 連続ドラマW「マークスの山」オリジナルサウンドトラック  \n"
     ]
    }
   ],
   "source": [
    "# Load song information\n",
    "id_information = pd.read_csv('../data/id_information.csv', sep='\\t')\n",
    "\n",
    "# Filter id_information to only include the top N recommended song IDs\n",
    "recommended_songs = id_information[id_information['id'].isin(top_n_song_ids)]\n",
    "\n",
    "# Print the details of the top N recommended songs\n",
    "print(f\"Top {N} recommended songs for user {specific_user_id} are:\")\n",
    "print(recommended_songs[['artist', 'song', 'album_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186ae71",
   "metadata": {},
   "source": [
    "## Analyzing and Displaying User's Recent Song History\n",
    "\n",
    "### 1. **Filter Songs for Specific User**:\n",
    "   - Extract rows from the DataFrame `df` where the `user_id` matches the specific user (`specific_user_id`). This subset contains all the songs interacted with by this particular user.\n",
    "\n",
    "### 2. **Sort Songs by Recent Play**:\n",
    "   - Sort the filtered data (`user_songs`) by the `timestamp` column in descending order to prioritize the most recent interactions. This sorted DataFrame is stored as `user_songs_sorted`.\n",
    "\n",
    "### 3. **Identify Last 5 Played Songs**:\n",
    "   - Retrieve the IDs of the last five songs played by this user from the top of the sorted DataFrame, ensuring these are the most recent songs interacted with.\n",
    "\n",
    "### 4. **Filter Song Metadata**:\n",
    "   - Use the song IDs (`last_5_song_ids`) to filter `id_information` to include only metadata for these last five songs. This step ensures that the information displayed pertains only to the most recent song interactions.\n",
    "\n",
    "### 5. **Display Song Information**:\n",
    "   - Print details about these last five songs, including the artist, song title, and album name, providing a comprehensive view of the user’s most recent music preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e7c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rPcvhlfan3sOTDX8' 'ilrbbVMFVbnwmdFp' 'OBkwaSaAAVVcBaag'\n",
      " 'NsNXlxbPuFnyPv9p' '6U91Xztu28VOYkmU']\n",
      "Information about the last 5 songs played:\n",
      "              artist              song                          album_name\n",
      "11445  Marty Robbins          Big Iron  Gunfighter Ballads And Trail Songs\n",
      "42102  Marty Robbins     Billy the Kid  Gunfighter Ballads And Trail Songs\n",
      "42687  Marty Robbins        Utah Carol  Gunfighter Ballads And Trail Songs\n",
      "78856      blink-182  When I Was Young                    Dogs Eating Dogs\n",
      "94075      blink-182        Boxing Day                    Dogs Eating Dogs\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for the specific user\n",
    "user_songs = df[df.user_id == specific_user_id]\n",
    "\n",
    "# Sort the data by the timestamp column in descending order\n",
    "user_songs_sorted = user_songs.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "last_5_song_ids = user_songs_sorted['song'].head(5).values\n",
    "print(last_5_song_ids)\n",
    "\n",
    "last_5_songs_info = id_information[id_information['id'].isin(last_5_song_ids)]\n",
    "print(\"Information about the last 5 songs played:\")\n",
    "print(last_5_songs_info[['artist', 'song', 'album_name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e2f06",
   "metadata": {},
   "source": [
    "## Generating and Comparing Predicted Recommendations with Actual Preferences\n",
    "\n",
    "### 1. **Define Function to Retrieve Actual Relevant Songs**:\n",
    "   - The `get_relevant_songs` function is designed to fetch the unique song IDs that a specific user has interacted with from the DataFrame `df`. This establishes a baseline of songs that are known to be relevant to the user.\n",
    "\n",
    "### 2. **Initialize Prediction and Actual Dictionaries**:\n",
    "   - Two dictionaries, `predictions` and `actual`, are initialized to store the predicted top song IDs and actual relevant song IDs for each user, respectively.\n",
    "\n",
    "### 3. **Iterate Over a Subset of Users**:\n",
    "   - Loop through each user ID in the test set. This looping facilitates the prediction and validation process for multiple users in a manageable subset.\n",
    "\n",
    "### 4. **Generate Predictions for Each User**:\n",
    "   - For each user:\n",
    "     - Create an input array (`user_input`) that repeats the user ID for each song, corresponding to the total number of unique songs (`M`).\n",
    "     - Predict interaction scores using the model for all songs with the prepared inputs. Flatten the result to simplify handling.\n",
    "     - Sort the predicted scores in descending order and extract the indices of the top `N` scores.\n",
    "     - Use `song_encoder.inverse_transform` to convert these indices back into original song IDs (`top_n_song_ids`).\n",
    "\n",
    "### 5. **Store Predictions and Actual Song IDs**:\n",
    "   - Store the top `N` predicted song IDs for each user in the `predictions` dictionary.\n",
    "   - Fetch and store the actual relevant songs for the user using `get_relevant_songs` and store them in the `actual` dictionary.\n",
    "\n",
    "### 6. **Output Progress**:\n",
    "   - Print the total number of users being processed and the current progress after each user's data is processed to monitor the computation and ensure it is proceeding correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e38be259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 1\n",
      "569/569 [==============================] - 0s 653us/step\n",
      "2303234 2\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 3\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 4\n",
      "569/569 [==============================] - 0s 549us/step\n",
      "2303234 5\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 6\n",
      "569/569 [==============================] - 0s 551us/step\n",
      "2303234 7\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 8\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 9\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 10\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 11\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 12\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 13\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 14\n",
      "569/569 [==============================] - 0s 549us/step\n",
      "2303234 15\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 16\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 17\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 18\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 19\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 20\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 21\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 22\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 23\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 24\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 25\n",
      "569/569 [==============================] - 0s 563us/step\n",
      "2303234 26\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 27\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 28\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 29\n",
      "569/569 [==============================] - 0s 553us/step\n",
      "2303234 30\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 31\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 32\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 33\n",
      "569/569 [==============================] - 0s 621us/step\n",
      "2303234 34\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 35\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 36\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 37\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 38\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 39\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 40\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 41\n",
      "569/569 [==============================] - 0s 542us/step\n",
      "2303234 42\n",
      "569/569 [==============================] - 0s 540us/step\n",
      "2303234 43\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 44\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 45\n",
      "569/569 [==============================] - 0s 569us/step\n",
      "2303234 46\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 47\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 48\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 49\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 50\n",
      "569/569 [==============================] - 0s 657us/step\n",
      "2303234 51\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 52\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 53\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 54\n",
      "569/569 [==============================] - 0s 625us/step\n",
      "2303234 55\n",
      "569/569 [==============================] - 0s 651us/step\n",
      "2303234 56\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 57\n",
      "569/569 [==============================] - 0s 676us/step\n",
      "2303234 58\n",
      "569/569 [==============================] - 0s 604us/step\n",
      "2303234 59\n",
      "569/569 [==============================] - 0s 646us/step\n",
      "2303234 60\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 61\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 62\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 63\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 64\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 65\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 66\n",
      "569/569 [==============================] - 0s 632us/step\n",
      "2303234 67\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 68\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 69\n",
      "569/569 [==============================] - 0s 655us/step\n",
      "2303234 70\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 71\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 72\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 73\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 74\n",
      "569/569 [==============================] - 0s 660us/step\n",
      "2303234 75\n",
      "569/569 [==============================] - 0s 632us/step\n",
      "2303234 76\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 77\n",
      "569/569 [==============================] - 0s 644us/step\n",
      "2303234 78\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 79\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 80\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 81\n",
      "569/569 [==============================] - 0s 618us/step\n",
      "2303234 82\n",
      "569/569 [==============================] - 0s 650us/step\n",
      "2303234 83\n",
      "569/569 [==============================] - 0s 621us/step\n",
      "2303234 84\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 85\n",
      "569/569 [==============================] - 0s 629us/step\n",
      "2303234 86\n",
      "569/569 [==============================] - 0s 669us/step\n",
      "2303234 87\n",
      "569/569 [==============================] - 0s 651us/step\n",
      "2303234 88\n",
      "569/569 [==============================] - 0s 655us/step\n",
      "2303234 89\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 90\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 91\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 92\n",
      "569/569 [==============================] - 0s 688us/step\n",
      "2303234 93\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 94\n",
      "569/569 [==============================] - 0s 630us/step\n",
      "2303234 95\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 96\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 97\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 98\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 99\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 100\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 101\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 102\n",
      "569/569 [==============================] - 0s 569us/step\n",
      "2303234 103\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 104\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 105\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 106\n",
      "569/569 [==============================] - 0s 558us/step\n",
      "2303234 107\n",
      "569/569 [==============================] - 0s 562us/step\n",
      "2303234 108\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 109\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 110\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 111\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 112\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 113\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 114\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 115\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 116\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 117\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 118\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 119\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 604us/step\n",
      "2303234 121\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 122\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 123\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 124\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 125\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 126\n",
      "569/569 [==============================] - 0s 637us/step\n",
      "2303234 127\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 128\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 129\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 130\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 131\n",
      "569/569 [==============================] - 0s 629us/step\n",
      "2303234 132\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 133\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 134\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 135\n",
      "569/569 [==============================] - 0s 637us/step\n",
      "2303234 136\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 137\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 138\n",
      "569/569 [==============================] - 0s 563us/step\n",
      "2303234 139\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 140\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 141\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 142\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 143\n",
      "569/569 [==============================] - 0s 625us/step\n",
      "2303234 144\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 145\n",
      "569/569 [==============================] - 0s 643us/step\n",
      "2303234 146\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 147\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 148\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 149\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 150\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 151\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 152\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 153\n",
      "569/569 [==============================] - 0s 629us/step\n",
      "2303234 154\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 155\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 156\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 157\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 158\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 159\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 160\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 161\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 162\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 163\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 164\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 165\n",
      "569/569 [==============================] - 0s 632us/step\n",
      "2303234 166\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 167\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 168\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 169\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 170\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 171\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 172\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 173\n",
      "569/569 [==============================] - 0s 563us/step\n",
      "2303234 174\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 175\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 176\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 177\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 178\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 179\n",
      "569/569 [==============================] - 0s 648us/step\n",
      "2303234 180\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 181\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 182\n",
      "569/569 [==============================] - 0s 644us/step\n",
      "2303234 183\n",
      "569/569 [==============================] - 0s 621us/step\n",
      "2303234 184\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 185\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 186\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 187\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 188\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 189\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 190\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 191\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 192\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 193\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 194\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 195\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 196\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 197\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 198\n",
      "569/569 [==============================] - 0s 630us/step\n",
      "2303234 199\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 200\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 201\n",
      "569/569 [==============================] - 0s 558us/step\n",
      "2303234 202\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 203\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 204\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 205\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 206\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 207\n",
      "569/569 [==============================] - 0s 591us/step\n",
      "2303234 208\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 209\n",
      "569/569 [==============================] - 0s 618us/step\n",
      "2303234 210\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 211\n",
      "569/569 [==============================] - 0s 644us/step\n",
      "2303234 212\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 213\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 214\n",
      "569/569 [==============================] - 0s 555us/step\n",
      "2303234 215\n",
      "569/569 [==============================] - 0s 630us/step\n",
      "2303234 216\n",
      "569/569 [==============================] - 0s 632us/step\n",
      "2303234 217\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 218\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 219\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 220\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 221\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 222\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 223\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 224\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 225\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 226\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 227\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 228\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 229\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 230\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 231\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 232\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 233\n",
      "569/569 [==============================] - 0s 637us/step\n",
      "2303234 234\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 235\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 236\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 237\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 238\n",
      "569/569 [==============================] - 0s 600us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2303234 239\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 240\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 241\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 242\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 243\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 244\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 245\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 246\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 247\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 248\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 249\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 250\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 251\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 252\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 253\n",
      "569/569 [==============================] - 0s 671us/step\n",
      "2303234 254\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 255\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 256\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 257\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 258\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 259\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 260\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 261\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 262\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 263\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 264\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 265\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 266\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 267\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 268\n",
      "569/569 [==============================] - 0s 553us/step\n",
      "2303234 269\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 270\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 271\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 272\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 273\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 274\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 275\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 276\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 277\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 278\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 279\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 280\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 281\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 282\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 283\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 284\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 285\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 286\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 287\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 288\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 289\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 290\n",
      "569/569 [==============================] - 0s 579us/step\n",
      "2303234 291\n",
      "569/569 [==============================] - 0s 632us/step\n",
      "2303234 292\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 293\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 294\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 295\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 296\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 297\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 298\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 299\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 300\n",
      "569/569 [==============================] - 0s 556us/step\n",
      "2303234 301\n",
      "569/569 [==============================] - 0s 648us/step\n",
      "2303234 302\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 303\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 304\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 305\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 306\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 307\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 308\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 309\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 310\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 311\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 312\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 313\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 314\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 315\n",
      "569/569 [==============================] - 0s 555us/step\n",
      "2303234 316\n",
      "569/569 [==============================] - 0s 630us/step\n",
      "2303234 317\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 318\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 319\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 320\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 321\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 322\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 323\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 324\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 325\n",
      "569/569 [==============================] - 0s 551us/step\n",
      "2303234 326\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 327\n",
      "569/569 [==============================] - 0s 636us/step\n",
      "2303234 328\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 329\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 330\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 331\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 332\n",
      "569/569 [==============================] - 0s 544us/step\n",
      "2303234 333\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 334\n",
      "569/569 [==============================] - 0s 658us/step\n",
      "2303234 335\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 336\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 337\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 338\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 339\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 340\n",
      "569/569 [==============================] - 0s 650us/step\n",
      "2303234 341\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 342\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 343\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 344\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 345\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 346\n",
      "569/569 [==============================] - 0s 625us/step\n",
      "2303234 347\n",
      "569/569 [==============================] - 0s 618us/step\n",
      "2303234 348\n",
      "569/569 [==============================] - 0s 549us/step\n",
      "2303234 349\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 350\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 351\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 352\n",
      "569/569 [==============================] - 0s 621us/step\n",
      "2303234 353\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 354\n",
      "569/569 [==============================] - 0s 569us/step\n",
      "2303234 355\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 356\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 358\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 359\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 360\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 361\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 362\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 363\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 364\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 365\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 366\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 367\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 368\n",
      "569/569 [==============================] - 0s 639us/step\n",
      "2303234 369\n",
      "569/569 [==============================] - 0s 629us/step\n",
      "2303234 370\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 371\n",
      "569/569 [==============================] - 0s 625us/step\n",
      "2303234 372\n",
      "569/569 [==============================] - 0s 562us/step\n",
      "2303234 373\n",
      "569/569 [==============================] - 0s 577us/step\n",
      "2303234 374\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 375\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 376\n",
      "569/569 [==============================] - 0s 546us/step\n",
      "2303234 377\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 378\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 379\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 380\n",
      "569/569 [==============================] - 0s 556us/step\n",
      "2303234 381\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 382\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 383\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 384\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 385\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 386\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 387\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 388\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 389\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 390\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 391\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 392\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 393\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 394\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 395\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 396\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 397\n",
      "569/569 [==============================] - 0s 555us/step\n",
      "2303234 398\n",
      "569/569 [==============================] - 0s 604us/step\n",
      "2303234 399\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 400\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 401\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 402\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 403\n",
      "569/569 [==============================] - 0s 614us/step\n",
      "2303234 404\n",
      "569/569 [==============================] - 0s 569us/step\n",
      "2303234 405\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 406\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 407\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 408\n",
      "569/569 [==============================] - 0s 655us/step\n",
      "2303234 409\n",
      "569/569 [==============================] - 0s 648us/step\n",
      "2303234 410\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 411\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 412\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 413\n",
      "569/569 [==============================] - 0s 655us/step\n",
      "2303234 414\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 415\n",
      "569/569 [==============================] - 0s 606us/step\n",
      "2303234 416\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 417\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 418\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 419\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 420\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 421\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 422\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 423\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 424\n",
      "569/569 [==============================] - 0s 572us/step\n",
      "2303234 425\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 426\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 427\n",
      "569/569 [==============================] - 0s 673us/step\n",
      "2303234 428\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 429\n",
      "569/569 [==============================] - 0s 625us/step\n",
      "2303234 430\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 431\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 432\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 433\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 434\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 435\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 436\n",
      "569/569 [==============================] - 0s 621us/step\n",
      "2303234 437\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 438\n",
      "569/569 [==============================] - 0s 609us/step\n",
      "2303234 439\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 440\n",
      "569/569 [==============================] - 0s 618us/step\n",
      "2303234 441\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 442\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 443\n",
      "569/569 [==============================] - 0s 627us/step\n",
      "2303234 444\n",
      "569/569 [==============================] - 0s 563us/step\n",
      "2303234 445\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 446\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 447\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 448\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 449\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 450\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 451\n",
      "569/569 [==============================] - 0s 551us/step\n",
      "2303234 452\n",
      "569/569 [==============================] - 0s 623us/step\n",
      "2303234 453\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 454\n",
      "569/569 [==============================] - 0s 583us/step\n",
      "2303234 455\n",
      "569/569 [==============================] - 0s 597us/step\n",
      "2303234 456\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 457\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 458\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 459\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 460\n",
      "569/569 [==============================] - 0s 569us/step\n",
      "2303234 461\n",
      "569/569 [==============================] - 0s 551us/step\n",
      "2303234 462\n",
      "569/569 [==============================] - 0s 581us/step\n",
      "2303234 463\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 464\n",
      "569/569 [==============================] - 0s 585us/step\n",
      "2303234 465\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 466\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 467\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 468\n",
      "569/569 [==============================] - 0s 620us/step\n",
      "2303234 469\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 470\n",
      "569/569 [==============================] - 0s 560us/step\n",
      "2303234 471\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 472\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 473\n",
      "569/569 [==============================] - 0s 574us/step\n",
      "2303234 474\n",
      "569/569 [==============================] - 0s 599us/step\n",
      "2303234 475\n",
      "569/569 [==============================] - 0s 611us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2303234 476\n",
      "569/569 [==============================] - 0s 567us/step\n",
      "2303234 477\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 478\n",
      "569/569 [==============================] - 0s 637us/step\n",
      "2303234 479\n",
      "569/569 [==============================] - 0s 588us/step\n",
      "2303234 480\n",
      "569/569 [==============================] - 0s 634us/step\n",
      "2303234 481\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 482\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 483\n",
      "569/569 [==============================] - 0s 595us/step\n",
      "2303234 484\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2303234 485\n",
      "569/569 [==============================] - 0s 639us/step\n",
      "2303234 486\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 487\n",
      "569/569 [==============================] - 0s 592us/step\n",
      "2303234 488\n",
      "569/569 [==============================] - 0s 565us/step\n",
      "2303234 489\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 490\n",
      "569/569 [==============================] - 0s 613us/step\n",
      "2303234 491\n",
      "569/569 [==============================] - 0s 593us/step\n",
      "2303234 492\n",
      "569/569 [==============================] - 0s 570us/step\n",
      "2303234 493\n",
      "569/569 [==============================] - 0s 600us/step\n",
      "2303234 494\n",
      "569/569 [==============================] - 0s 611us/step\n",
      "2303234 495\n",
      "569/569 [==============================] - 0s 586us/step\n",
      "2303234 496\n",
      "569/569 [==============================] - 0s 607us/step\n",
      "2303234 497\n",
      "569/569 [==============================] - 0s 616us/step\n",
      "2303234 498\n",
      "569/569 [==============================] - 0s 602us/step\n",
      "2303234 499\n",
      "569/569 [==============================] - 0s 590us/step\n",
      "2303234 500\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_songs(user_id, df):\n",
    "    return df[df.user_id == user_id]['song'].unique()\n",
    "\n",
    "predictions = {}\n",
    "actual = {}\n",
    "\n",
    "i = 0\n",
    "# Get predictions and actual relevant songs\n",
    "for user_id in user_ids_test[:500]: \n",
    "    # Predict top N songs\n",
    "    user_input = np.array([user_id] * M)\n",
    "    predicted_interactions = model.predict([user_input, song_input]).flatten()\n",
    "    top_n_indices = np.argsort(predicted_interactions)[::-1][:N]\n",
    "    top_n_song_ids = song_encoder.inverse_transform(top_n_indices)\n",
    "\n",
    "    # Store the top N song IDs\n",
    "    predictions[user_id] = top_n_song_ids.tolist()\n",
    "\n",
    "    # Get actual relevant songs\n",
    "    actual_relevant_songs = get_relevant_songs(user_id, df)\n",
    "    actual[user_id] = actual_relevant_songs.tolist()\n",
    "    i += 1\n",
    "    print(len(user_ids_test), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c383679",
   "metadata": {},
   "source": [
    "## Recommendation System Evaluation Metrics\n",
    "\n",
    "### Metric Calculations\n",
    "\n",
    "#### 1. **Precision at K**:\n",
    "   - Measures the proportion of recommended items in the top-K set that are relevant.\n",
    "\n",
    "#### 2. **Recall at K**:\n",
    "   - Assesses how many relevant items are found in the top-K recommendations.\n",
    "\n",
    "#### 3. **Mean Average Precision at K (MAP@K)**:\n",
    "   - Computes the mean of the average precision scores for each user, considering only the top-K recommendations.\n",
    "\n",
    "#### 4. **Mean Reciprocal Rank (MRR)**:\n",
    "   - Calculates the average of the reciprocal of the rank of the first relevant item among the recommendations.\n",
    "\n",
    "#### 5. **Normalized Discounted Cumulative Gain at K (NDCG@K)**:\n",
    "   - Evaluates the gain of a recommendation based on its position in the result list, giving higher importance to hits at top ranks.\n",
    "\n",
    "### Functions Defined\n",
    "\n",
    "- **`precision_at_k`**: Compares the top-K predicted items to the actual relevant items for each user to calculate precision.\n",
    "- **`recall_at_k`**: Identifies how many of the relevant items appear in the top-K predictions for each user.\n",
    "- **`mean_avg_precision_at_k`** and **`mean_average_precision_at_k`**: Both calculate the average precision at K for predictions against actual data.\n",
    "- **`mean_reciprocal_rank`**: Computes the average reciprocal rank where the rank is the position of the first relevant recommendation.\n",
    "- **`dcg_at_k`**: Computes the Discounted Cumulative Gain at K, a measure of ranking quality.\n",
    "- **`ndcg_at_k`**: Normalizes the DCG at K by the ideal or perfect DCG at K, providing a measure of the model's performance relative to the best possible scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bbd6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0041666666666666675\n",
      "Recall@10: 0.0009490057461604342\n",
      "MAP@10: 0.0015367535903250192\n",
      "MRR: 0.015334467120181404\n",
      "NDCG@10: 0.004696199420932304\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(actual, predicted, k):\n",
    "    precision_scores = []\n",
    "    for user_id in actual:\n",
    "        # Initialize true positives count\n",
    "        true_positives = 0\n",
    "        # Check if user exists in predictions\n",
    "        if user_id in predicted and len(predicted[user_id]) >= k:\n",
    "            # Count the number of relevant items in the top k predictions\n",
    "            true_positives = len(set(predicted[user_id][:k]) & set(actual[user_id]))\n",
    "        # Calculate precision for this user\n",
    "        precision = true_positives / float(k)\n",
    "        precision_scores.append(precision)\n",
    "    # Return the average precision at k for all users\n",
    "    return sum(precision_scores) / len(precision_scores)\n",
    "\n",
    "\n",
    "def recall_at_k(actual, predicted, k):\n",
    "    recall_scores = []\n",
    "    for user_id in actual:\n",
    "        # Initialize true positives count\n",
    "        true_positives = 0\n",
    "        # Check if user exists in predictions\n",
    "        if user_id in predicted:\n",
    "            # Count the number of relevant items in the top k predictions\n",
    "            true_positives = len(set(predicted[user_id][:k]) & set(actual[user_id]))\n",
    "            recall = true_positives / float(len(actual[user_id]))\n",
    "        else:\n",
    "            # If no predictions for the user, recall is 0\n",
    "            recall = 0.0\n",
    "        recall_scores.append(recall)\n",
    "    # Return the average recall at k for all users\n",
    "    return sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "\n",
    "def avg_precision_at_k(actual, predicted, k=10):\n",
    "    ap_sum = 0\n",
    "    for user, true_items in actual.items():\n",
    "        pred_items = predicted[user][:k]\n",
    "        hits = 0\n",
    "        sum_precs = 0\n",
    "        for i, p in enumerate(pred_items):\n",
    "            if p in true_items:\n",
    "                hits += 1\n",
    "                sum_precs += hits / (i + 1.0)\n",
    "        ap_sum += sum_precs / min(len(true_items), k)\n",
    "    return ap_sum / len(actual)\n",
    "\n",
    "\n",
    "def mean_avg_precision_at_k(actual, predicted, k=10):\n",
    "    return avg_precision_at_k(actual, predicted, k)\n",
    "\n",
    "\n",
    "def mean_average_precision_at_k(actual, predicted, k=10):\n",
    "    AP_sum = 0.0\n",
    "    for user_id in actual:\n",
    "        if user_id in predicted:\n",
    "            pred_items = predicted[user_id][:k]\n",
    "            hits = 0\n",
    "            sum_precisions = 0\n",
    "            for i, p in enumerate(pred_items):\n",
    "                if p in actual[user_id] and p not in pred_items[:i]:\n",
    "                    hits += 1\n",
    "                    sum_precisions += hits / (i + 1.0)\n",
    "            AP_sum += sum_precisions / min(len(actual[user_id]), k)\n",
    "    return AP_sum / len(actual)\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(actual, predicted):\n",
    "    MRR_sum = 0.0\n",
    "    for user_id in actual:\n",
    "        if user_id in predicted:\n",
    "            pred_items = predicted[user_id]\n",
    "            for rank, p in enumerate(pred_items, start=1):\n",
    "                if p in actual[user_id]:\n",
    "                    MRR_sum += 1.0 / rank\n",
    "                    break\n",
    "    return MRR_sum / len(actual)\n",
    "\n",
    "\n",
    "def dcg_at_k(relevances, k):\n",
    "    relevances = np.asfarray(relevances)[:k]\n",
    "    if relevances.size:\n",
    "        return np.sum(relevances / np.log2(np.arange(2, relevances.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k=10):\n",
    "    NDCG_sum = 0.0\n",
    "    for user_id in actual:\n",
    "        if user_id in predicted:\n",
    "            pred_items = predicted[user_id][:k]\n",
    "            true_relevances = [1 if item in actual[user_id] else 0 for item in pred_items]\n",
    "            ideal_relevances = [1] * len(actual[user_id])\n",
    "            NDCG_sum += dcg_at_k(true_relevances, k) / dcg_at_k(ideal_relevances, k)\n",
    "    return NDCG_sum / len(actual)\n",
    "\n",
    "k = 10\n",
    "precision = precision_at_k(actual, predictions, k)\n",
    "recall = recall_at_k(actual, predictions, k)\n",
    "map_k = mean_average_precision_at_k(actual, predictions, k)\n",
    "mrr = mean_reciprocal_rank(actual, predictions)\n",
    "ndcg_k = ndcg_at_k(actual, predictions, k)\n",
    "\n",
    "print(f\"Precision@{k}: {precision}\")\n",
    "print(f\"Recall@{k}: {recall}\")\n",
    "print(f\"MAP@{k}: {map_k}\")\n",
    "print(f\"MRR: {mrr}\")\n",
    "print(f\"NDCG@{k}: {ndcg_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18949e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
