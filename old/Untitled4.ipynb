{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f28a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Flatten, concatenate, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3a5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = '../data/id_metadata.csv'\n",
    "listening_history_path = '../data/listening_history.csv'\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_path, delimiter='\\t')\n",
    "listening_history_df = pd.read_csv(listening_history_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff913b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listening_history_df = listening_history_df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cd52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "listening_history_df['timestamp'] = pd.to_datetime(listening_history_df['timestamp'])\n",
    "listening_history_df.sort_values(by=['user', 'timestamp'], inplace=True)\n",
    "user_encoder = LabelEncoder()\n",
    "song_encoder = LabelEncoder()\n",
    "listening_history_df['user_id'] = user_encoder.fit_transform(listening_history_df['user'])\n",
    "listening_history_df['song_id'] = song_encoder.fit_transform(listening_history_df['song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149d2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_time_of_day(timestamp):\n",
    "    hour = timestamp.hour\n",
    "    if 4 <= hour < 12:\n",
    "        return 1  # 4:00 AM to 11:59 AM\n",
    "    elif 12 <= hour < 20:\n",
    "        return 2  # 12:00 PM to 7:59 PM\n",
    "    else:\n",
    "        return 3  # 8:00 PM to 3:59 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7236a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listening_history_df['time_of_day'] = listening_history_df['timestamp'].apply(classify_time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d40bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>DaTQ53TUmfP93FSr</td>\n",
       "      <td>2019-02-20 12:28:00</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>dGeyvi5WCOjDU7da</td>\n",
       "      <td>2019-02-20 12:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>qUm54NYOjeFhmKYx</td>\n",
       "      <td>2019-02-20 12:48:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>FtnuMT1DlevSR2n5</td>\n",
       "      <td>2019-02-20 12:52:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_007XIjOr</td>\n",
       "      <td>LHETTZcSZLeaVOGh</td>\n",
       "      <td>2019-02-20 13:09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>user_06kNhNYa</td>\n",
       "      <td>ovi7JfEwHwZVac7L</td>\n",
       "      <td>2019-01-27 20:35:00</td>\n",
       "      <td>26</td>\n",
       "      <td>3551</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>user_06kNhNYa</td>\n",
       "      <td>xfSE1aB7yIH42NPi</td>\n",
       "      <td>2019-01-27 20:39:00</td>\n",
       "      <td>26</td>\n",
       "      <td>4208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>user_06kNhNYa</td>\n",
       "      <td>E3iQOe4M979du9C8</td>\n",
       "      <td>2019-01-28 16:10:00</td>\n",
       "      <td>26</td>\n",
       "      <td>1023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>user_06kNhNYa</td>\n",
       "      <td>LuFeu9smK7RiTZqD</td>\n",
       "      <td>2019-01-28 16:18:00</td>\n",
       "      <td>26</td>\n",
       "      <td>1546</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>user_06kNhNYa</td>\n",
       "      <td>USxnLgstA31jmG6q</td>\n",
       "      <td>2019-01-28 16:46:00</td>\n",
       "      <td>26</td>\n",
       "      <td>2148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user              song           timestamp  user_id  song_id  \\\n",
       "0     user_007XIjOr  DaTQ53TUmfP93FSr 2019-02-20 12:28:00        0      995   \n",
       "1     user_007XIjOr  dGeyvi5WCOjDU7da 2019-02-20 12:35:00        0     2727   \n",
       "2     user_007XIjOr  qUm54NYOjeFhmKYx 2019-02-20 12:48:00        0     3678   \n",
       "3     user_007XIjOr  FtnuMT1DlevSR2n5 2019-02-20 12:52:00        0     1146   \n",
       "4     user_007XIjOr  LHETTZcSZLeaVOGh 2019-02-20 13:09:00        0     1503   \n",
       "...             ...               ...                 ...      ...      ...   \n",
       "9995  user_06kNhNYa  ovi7JfEwHwZVac7L 2019-01-27 20:35:00       26     3551   \n",
       "9996  user_06kNhNYa  xfSE1aB7yIH42NPi 2019-01-27 20:39:00       26     4208   \n",
       "9997  user_06kNhNYa  E3iQOe4M979du9C8 2019-01-28 16:10:00       26     1023   \n",
       "9998  user_06kNhNYa  LuFeu9smK7RiTZqD 2019-01-28 16:18:00       26     1546   \n",
       "9999  user_06kNhNYa  USxnLgstA31jmG6q 2019-01-28 16:46:00       26     2148   \n",
       "\n",
       "      time_of_day  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               2  \n",
       "...           ...  \n",
       "9995            3  \n",
       "9996            3  \n",
       "9997            2  \n",
       "9998            2  \n",
       "9999            2  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listening_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a142a069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listening_history_df['timestamp'] = (listening_history_df['timestamp'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d42f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the 'id' column in metadata_df corresponds to the song ID\n",
    "# Set 'id' as the index for easy lookup\n",
    "metadata_df.set_index('id', inplace=True)\n",
    "# Selecting the columns to be scaled\n",
    "features_to_scale = ['popularity', 'release', 'danceability', 'energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "# Fit the scaler to the metadata features\n",
    "scaler = MinMaxScaler()\n",
    "metadata_df[features_to_scale] = scaler.fit_transform(metadata_df[features_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b76e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the get_song_metadata function will return scaled values\n",
    "def get_song_metadata(song_id):\n",
    "    if song_id in metadata_df.index:\n",
    "        metadata = metadata_df.loc[song_id, features_to_scale]\n",
    "        return metadata.values\n",
    "    else:\n",
    "        return np.zeros(len(features_to_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6af761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4842105263157895, 0.9940357852882702, 0.5981781376518218, 0.513,\n",
       "       0.6363636363636364, 0.0, 0.2635270541082164, 0.7089578967736092,\n",
       "       0.06372524451262468], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_song_metadata('0010xmHR6UICBOYT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa733f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# classify_time_of_day(pd.to_datetime(user_df['timestamp'].tolist()[0], unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3542755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "users = listening_history_df['user_id'].unique()\n",
    "song_sequences = []\n",
    "timestamp_sequences = []\n",
    "next_song_labels = []\n",
    "metadata_sequences = []\n",
    "time_of_day_sequences = []  # To store time-of-day sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "664752c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user_df = listening_history_df[listening_history_df['user_id'] == user]\n",
    "    user_songs = user_df['song_id'].tolist()\n",
    "    user_timestamps = user_df['timestamp'].tolist()\n",
    "    user_time_of_day = user_df['time_of_day'].tolist()  # Fetch time-of-day data\n",
    "\n",
    "    for i in range(1, len(user_songs)):\n",
    "        end_idx = min(i + sequence_length, len(user_songs))\n",
    "        start_idx = max(0, end_idx - sequence_length)\n",
    "\n",
    "        song_sequence = user_songs[start_idx:end_idx]\n",
    "        timestamp_sequence = user_timestamps[start_idx:end_idx]\n",
    "        metadata_sequence = [get_song_metadata(song) for song in user_songs[start_idx:end_idx]]\n",
    "        time_of_day_sequence = user_time_of_day[start_idx:end_idx]  # Use the time-of-day data\n",
    "\n",
    "        if len(song_sequence) == sequence_length:\n",
    "            song_sequences.append(song_sequence)\n",
    "            timestamp_sequences.append(timestamp_sequence)\n",
    "            metadata_sequences.append(metadata_sequence)\n",
    "            time_of_day_sequences.append(time_of_day_sequence)\n",
    "\n",
    "            if i + 1 < len(user_songs):\n",
    "                next_song_labels.append(user_songs[i + 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82eee2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user_input (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " song_input (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " time_of_day_input (InputLayer)  [(None, 10)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 10, 50)       1350        ['user_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 10, 50)       217900      ['song_input[0][0]']             \n",
      "                                                                                                  \n",
      " metadata_input (InputLayer)    [(None, 10, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 10, 3)        9           ['time_of_day_input[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 112)      0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]',            \n",
      "                                                                  'metadata_input[0][0]',         \n",
      "                                                                  'embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          123392      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4358)         283270      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 634,177\n",
      "Trainable params: 634,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users and songs\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_songs = len(song_encoder.classes_)\n",
    "metadata_dim = len(features_to_scale)\n",
    "\n",
    "# Embedding dimensions\n",
    "user_embedding_dim = 50\n",
    "song_embedding_dim = 50\n",
    "time_of_day_dim = 3  # Assuming 4 categories for time of day\n",
    "\n",
    "# Model architecture\n",
    "user_input = Input(shape=(sequence_length,), name='user_input')\n",
    "user_embedding = Embedding(num_users, user_embedding_dim, input_length=sequence_length)(user_input)\n",
    "\n",
    "song_input = Input(shape=(sequence_length,), name='song_input')\n",
    "song_embedding = Embedding(num_songs, song_embedding_dim, input_length=sequence_length)(song_input)\n",
    "\n",
    "metadata_input = Input(shape=(sequence_length, metadata_dim), name='metadata_input')\n",
    "# No need to flatten the metadata\n",
    "# reshape_metadata = Reshape((sequence_length, metadata_dim))(metadata_input)\n",
    "\n",
    "time_of_day_input = Input(shape=(sequence_length,), name='time_of_day_input')\n",
    "time_of_day_embedding = Embedding(time_of_day_dim, time_of_day_dim, input_length=sequence_length)(time_of_day_input)\n",
    "\n",
    "concatenated = concatenate([user_embedding, song_embedding, metadata_input, time_of_day_embedding])\n",
    "\n",
    "lstm_layer = LSTM(128, return_sequences=False)(concatenated)\n",
    "dense_layer = Dense(64, activation='relu')(lstm_layer)\n",
    "dropout_layer = Dropout(0.2)(dense_layer)\n",
    "output_layer = Dense(num_songs, activation='softmax')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=[user_input, song_input, metadata_input, time_of_day_input], outputs=output_layer)\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db64b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure the lengths of song_sequences and next_song_labels are the same\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(song_sequences) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(next_song_labels)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# # Create user_array\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# user_array = np.array([user_id for user_id in user_df['user_id'].unique() for _ in range(len(song_sequences)//len(user_df['user_id'].unique()))])\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# # Check lengths again\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# assert len(user_array) == len(song_sequences) == len(next_song_labels)\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ensure the lengths of song_sequences and next_song_labels are the same\n",
    "assert len(song_sequences) == len(next_song_labels)\n",
    "\n",
    "# Create user_array\n",
    "user_array = np.array([user_id for user_id in user_df['user_id'].unique() for _ in range(len(song_sequences)//len(user_df['user_id'].unique()))])\n",
    "\n",
    "# Check lengths again\n",
    "assert len(user_array) == len(song_sequences) == len(next_song_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f67da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_array = np.array([np.full(shape=(sequence_length,), fill_value=user_id) for user_id, _ in enumerate(song_sequences)])\n",
    "song_array = np.array(song_sequences)\n",
    "metadata_array = np.array(metadata_sequences)\n",
    "time_of_day_array = np.array(time_of_day_sequences)\n",
    "label_array = np.array(next_song_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af9838e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9973, 9946]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m  \u001b[38;5;66;03m# 20% of the data will be used for validation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Splitting the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_user_array, val_user_array, train_label_array, val_label_array \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m train_song_array, val_song_array \u001b[38;5;241m=\u001b[39m train_test_split(song_array, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      7\u001b[0m train_metadata_array, val_metadata_array \u001b[38;5;241m=\u001b[39m train_test_split(metadata_array, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\2023-Kolek-Musical_context-aware_recommendation_using_neural_networks\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\Desktop\\2023-Kolek-Musical_context-aware_recommendation_using_neural_networks\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Desktop\\2023-Kolek-Musical_context-aware_recommendation_using_neural_networks\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9973, 9946]"
     ]
    }
   ],
   "source": [
    "# Splitting parameters\n",
    "test_size = 0.2  # 20% of the data will be used for validation\n",
    "\n",
    "# Splitting the data\n",
    "train_user_array, val_user_array, train_label_array, val_label_array = train_test_split(user_array, label_array, test_size=test_size, random_state=42)\n",
    "train_song_array, val_song_array = train_test_split(song_array, test_size=test_size, random_state=42)\n",
    "train_metadata_array, val_metadata_array = train_test_split(metadata_array, test_size=test_size, random_state=42)\n",
    "train_time_of_day_array, val_time_of_day_array = train_test_split(time_of_day_array, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d5293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa01277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc099d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_sequences_padded = pad_sequences(song_sequences, maxlen=sequence_length)\n",
    "timestamp_sequences_padded = pad_sequences(timestamp_sequences, maxlen=sequence_length)\n",
    "next_song_labels = np.array(next_song_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming metadata_embedding_size and time_of_day_size are defined based on your data\n",
    "# def create_model_with_lstm(num_users, num_songs, sequence_length, metadata_embedding_size, time_of_day_size, num_features=0, embedding_size=50, lstm_units=64):    # Existing input layers\n",
    "#     user_sequence_input = Input(shape=(sequence_length,), name='user_sequence_input')\n",
    "#     song_sequence_input = Input(shape=(sequence_length,), name='song_sequence_input')\n",
    "#     timestamp_input = Input(shape=(sequence_length,), name='timestamp_input')\n",
    "\n",
    "#     # New input layers for song metadata and time of day\n",
    "#     song_metadata_input = Input(shape=(sequence_length, metadata_embedding_size), name='song_metadata_input')\n",
    "#     time_of_day_input = Input(shape=(sequence_length, time_of_day_size), name='time_of_day_input')\n",
    "\n",
    "#     # Embedding layers\n",
    "#     user_embedding = Embedding(output_dim=embedding_size, input_dim=num_users, input_length=sequence_length, name='user_embedding')(user_sequence_input)\n",
    "#     song_embedding = Embedding(output_dim=embedding_size, input_dim=num_songs, input_length=sequence_length, name='song_embedding')(song_sequence_input)\n",
    "\n",
    "#     # Flatten embeddings\n",
    "#     user_vec = Flatten()(user_embedding)\n",
    "#     song_vec = Flatten()(song_embedding)\n",
    "\n",
    "#     # Combine all inputs\n",
    "#     combined_input = concatenate([\n",
    "#         user_vec, \n",
    "#         song_vec, \n",
    "#         Flatten()(timestamp_input), \n",
    "#         Flatten()(song_metadata_input), \n",
    "#         Flatten()(time_of_day_input)\n",
    "#     ])\n",
    "\n",
    "#     # LSTM layer\n",
    "#     lstm_layer = LSTM(lstm_units, return_sequences=False)(Reshape((sequence_length, -1))(combined_input))\n",
    "\n",
    "#     # Concatenate with other attributes\n",
    "#     concat = concatenate([lstm_layer, other_input])\n",
    "\n",
    "#     # Dense layers\n",
    "#     dense = Dense(256, activation='relu')(concat)\n",
    "#     dropout = Dropout(0.5)(dense)\n",
    "#     output = Dense(num_songs, activation='softmax')(dropout)\n",
    "\n",
    "#     # Create and compile the model\n",
    "#     model = Model(inputs=[user_sequence_input, song_sequence_input, timestamp_input, song_metadata_input, time_of_day_input], outputs=output)\n",
    "#     model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "def create_model(sequence_length, num_songs, num_users, metadata_embedding_size):\n",
    "    # Define input layers\n",
    "    song_input = Input(shape=(sequence_length,), name='song_input')\n",
    "    timestamp_input = Input(shape=(sequence_length, 1), name='timestamp_input')\n",
    "    metadata_input = Input(shape=(sequence_length, metadata_embedding_size), name='metadata_input')\n",
    "    time_of_day_input = Input(shape=(sequence_length, 1), name='time_of_day_input')  # Assuming time_of_day is a single value per timestep\n",
    "\n",
    "    # Embedding layer for songs\n",
    "    song_embedding = Embedding(input_dim=num_songs, output_dim=50, input_length=sequence_length)(song_input)\n",
    "\n",
    "    # LSTM layer for songs\n",
    "    song_lstm = LSTM(64, return_sequences=False)(song_embedding)\n",
    "\n",
    "    # Flatten other inputs\n",
    "    flattened_timestamp = Flatten()(timestamp_input)\n",
    "    flattened_metadata = Flatten()(metadata_input)\n",
    "    flattened_time_of_day = Flatten()(time_of_day_input)\n",
    "\n",
    "    # Combine all inputs\n",
    "    combined = concatenate([song_lstm, flattened_timestamp, flattened_metadata, flattened_time_of_day])\n",
    "\n",
    "    # Dense layers\n",
    "    dense1 = Dense(256, activation='relu')(combined)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    output = Dense(num_songs, activation='softmax')(dropout1)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = Model(inputs=[song_input, timestamp_input, metadata_input, time_of_day_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_songs = len(np.unique(song_sequences_padded))\n",
    "num_users = len(users)  # or replace with the actual number of unique users\n",
    "metadata_embedding_size = len(features_to_scale)  # Based on your scaled metadata features\n",
    "\n",
    "# Create the model\n",
    "model = create_model(sequence_length, num_songs, num_users, metadata_embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa511ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each metadata sequence since they are currently a list of arrays\n",
    "metadata_sequences_flat = [[item for sublist in sequence for item in sublist] for sequence in metadata_sequences]\n",
    "\n",
    "# Pad the flattened metadata sequences\n",
    "metadata_sequences_padded = pad_sequences(metadata_sequences_flat, maxlen=sequence_length * len(features_to_scale), dtype='float32')\n",
    "\n",
    "# Reshape the metadata to have the correct form for the LSTM layer\n",
    "metadata_sequences_padded = metadata_sequences_padded.reshape(-1, sequence_length, len(features_to_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b5bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure the time_of_day_sequences is a numpy array with an extra dimension\n",
    "timestamp_sequences_padded_3d = np.expand_dims(timestamp_sequences_padded, axis=-1)\n",
    "\n",
    "model.fit(\n",
    "    [song_sequences_padded, timestamp_sequences_padded_3d, metadata_sequences_padded, time_of_day_sequences_padded],\n",
    "    next_song_labels,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36bd0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each metadata sequence since they are currently a list of arrays\n",
    "metadata_sequences_flat = [[item for sublist in sequence for item in sublist] for sequence in metadata_sequences]\n",
    "\n",
    "# Pad the flattened metadata sequences\n",
    "metadata_sequences_padded = pad_sequences(metadata_sequences_flat, maxlen=sequence_length * len(features_to_scale), dtype='float32')\n",
    "\n",
    "# Reshape the metadata to have the correct form for the LSTM layer\n",
    "metadata_sequences_padded = metadata_sequences_padded.reshape(-1, sequence_length, len(features_to_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_day_sequences_padded = pad_sequences(time_of_day_sequences, maxlen=sequence_length, padding='post', dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ad08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_users = len(listening_history_df['user_id'].unique())\n",
    "num_songs = len(listening_history_df['song_id'].unique())\n",
    "metadata_embedding_size = len(features_to_scale)  # Number of features in song metadata\n",
    "time_of_day_size = 0  # Update this if you add time-of-day information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c01243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "song_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ae2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59439333",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0cee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_day_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Corrected model creation call\n",
    "model = create_model_with_lstm(num_users, num_songs, sequence_length, metadata_embedding_size, time_of_day_size)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    [song_sequences_padded, song_sequences_padded, timestamp_sequences_padded, metadata_sequences_padded, time_of_day_sequences_padded],\n",
    "    next_song_labels,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf47b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
